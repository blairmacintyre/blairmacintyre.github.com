@INPROCEEDINGS{6402552, 
author={J. Chen and G. Turk and B. MacIntyre}, 
booktitle={Mixed and Augmented Reality (ISMAR), 2012 IEEE International Symposium on}, 
title={A non-photorealistic rendering framework with temporal coherence for augmented reality}, 
year={2012}, 
pages={151-160}, 
abstract={Many augmented reality (AR) applications require a seamless blending of real and virtual content as key to increased immersion and improved user experiences. Photorealistic and non-photorealistic rendering (NPR) are two ways to achieve this goal. Compared with photorealistic rendering, NPR stylizes both the real and virtual content and makes them indistinguishable. Maintaining temporal coherence is a key challenge in NPR. We propose a NPR framework with support for temporal coherence by leveraging model-space information. Our systems targets painterly rendering styles of NPR. There are three major steps in this rendering framework for creating coherent results: tensor field creation, brush anchor placement, and brush stroke reshaping. To achieve temporal coherence for the final rendered results, we propose a new projection-based surface sampling algorithm which generates anchor points on model surfaces. The 2D projections of these samples are uniformly distributed in image space for optimal brush stroke placement. We also propose a general method for averaging various properties of brush stroke textures, such as their skeletons and colors, to further improve the temporal coherence. We apply these methods to both static and animated models to create a painterly rendering style for AR. Compared with existing image space algorithms our method renders AR with NPR effects with a high degree of coherence.}, 
keywords={augmented reality;rendering (computer graphics);sampling methods;2D projection;NPR;anchor point;animated model;augmented reality;brush anchor placement;brush stroke reshaping;brush stroke texture;model-space information;nonphotorealistic rendering;projection-based surface sampling algorithm;static model;temporal coherence;tensor field creation;Algorithm design and analysis;Brushes;Coherence;Computational modeling;Rendering (computer graphics);Solid modeling;Tensile stress;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, Augmented, and Virtual Realities;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—Virtual Reality}, 
doi={10.1109/ISMAR.2012.6402552}, 
month={Nov},}

@INPROCEEDINGS{5643575, 
author={J. Chen and G. Turk and B. MacIntyre}, 
booktitle={Mixed and Augmented Reality (ISMAR), 2010 9th IEEE International Symposium on}, 
title={Painterly rendering with coherence for augmented reality}, 
year={2010}, 
pages={217-218}, 
abstract={A seamless blending of the real and virtual worlds is key to increased immersion and improved user experiences for augmented reality (AR). Photorealistic and non-photorealistic rendering (NPR) are two ways to achieve this goal. Non-photorealistic rendering creates an abstract version of both the real and virtual world by stylization to make them indistinguishable. We presented a painterly rendering algorithm for AR applications. This algorithm paints composed AR video frames with bump-mapping curly brushstrokes. Tensor fields are created for each frame to define direction for brushstrokes. The anchor point of a brushstroke is tracked or warped from frame to frame. Brushstrokes are also reshaped to provide better temporal coherence. The major difference between our algorithm and existing NPR work in general graphics and AR/VR areas is we use feature points across composed AR video frames to maintain coherence in the rendering.}, 
keywords={augmented reality;rendering (computer graphics);video signal processing;AR video frame;abstract version;augmented reality;brushstroke;bump mapping;feature point;nonphotorealistic rendering;painterly rendering;temporal coherence;virtual world;Augmented reality;Coherence;Paints;Pixel;Rendering (computer graphics);Streaming media;Tensile stress;Non-photorealistic rendering;augmented reality;painterly rendering;temporal coherence}, 
doi={10.1109/ISMAR.2010.5643575}, 
month={Oct},}

@ARTICLE{6516495, 
author={B. MacIntyre and H. Rouzati and M. Lechner}, 
journal={IEEE Computer Graphics and Applications}, 
title={Walled Gardens: Apps and Data as Barriers to Augmenting Reality}, 
year={2013}, 
volume={33}, 
number={3}, 
pages={77-81}, 
abstract={For augmented reality (AR) to reach its potential, AR content from multiple distinct sources must be simultaneously displayed in a more unified manner than is possible given today's application-centric environments. AR browsers and AR-enabled Web browsers point toward the functionalities that OSs must incorporate to fully support AR content. Also, application developers need richer forms of content describing the physical world and the objects in it. Standards such as ARML (Augmented Reality Markup Language) 2.0 have begun providing the glue needed to bind AR content to the physical world.}, 
keywords={XML;augmented reality;online front-ends;operating systems (computers);AR browsers;AR content;AR-enabled Web browsers;ARML 2.0;application developers;application-centric environments;augmented reality markup language 2.0;multiple distinct sources;walled gardens;Augmented reality;Mobile communication;Three dimensional displays;ARML 2.0;augmented reality;computer graphics;mobile computing}, 
doi={10.1109/MCG.2013.51}, 
ISSN={0272-1716}, 
month={May},}

@INPROCEEDINGS{6484002, 
author={I. Kulka and B. MacIntyre and M. Gandy and J. D. Bolter}, 
booktitle={Mixed and Augmented Reality (ISMAR-AMH), 2012 IEEE International Symposium on}, 
title={Plants and zombies: Two use cases for on-location panorama viewing in handheld mobile AR}, 
year={2012}, 
pages={103-104}, 
abstract={Panoramas, as a medium, have traditionally provided viewers with an encompassing experience of distant locations. In recent years, this experience has been augmented by combining handheld orientation sensors with digital panoramas to create mixed reality experiences that transform mobile devices into windows to the remote. Less explored, have been the mixed reality opportunities afforded through the viewing of mobile panoramas non-remotely, at or near their real world epicenters. This paper presents two handheld AR web applications, running on publicly available hardware and software, that utilize panoramas to facilitate both remote and on-location AR experiences. It explores how the experience and the utility of a panorama differ depending on the location in which it is viewed.}, 
keywords={Augmented reality;Legged locomotion;Media;Mobile communication;TV;Transforms;augmented reality;panorama;transmedia}, 
doi={10.1109/ISMAR-AMH.2012.6484002}, 
month={Nov},}

@ARTICLE{963459, 
author={R. Azuma and Y. Baillot and R. Behringer and S. Feiner and S. Julier and B. MacIntyre}, 
journal={IEEE Computer Graphics and Applications}, 
title={Recent advances in augmented reality}, 
year={2001}, 
volume={21}, 
number={6}, 
pages={34-47}, 
abstract={In 1997, Azuma published a survey on augmented reality (AR). Our goal is to complement, rather than replace, the original survey by presenting representative examples of the new advances. We refer one to the original survey for descriptions of potential applications (such as medical visualization, maintenance and repair of complex equipment, annotation, and path planning); summaries of AR system characteristics (such as the advantages and disadvantages of optical and video approaches to blending virtual and real, problems in display focus and contrast, and system portability); and an introduction to the crucial problem of registration, including sources of registration error and error-reduction strategies}, 
keywords={augmented reality;annotation;augmented reality;complex equipment maintenance;complex equipment repair;error reduction strategies;medical visualization;path planning;registration;Augmented reality;Calibration;Cameras;Head;Laser beams;Lenses;Liquid crystal displays;Optical modulation;Retina;Virtual environment}, 
doi={10.1109/38.963459}, 
ISSN={0272-1716}, 
month={Nov},}

@INPROCEEDINGS{880927, 
author={B. MacIntyre and E. Machado Coelho}, 
booktitle={Augmented Reality, 2000. (ISAR 2000). Proceedings. IEEE and ACM International Symposium on}, 
title={Adapting to dynamic registration errors using level of error (LOE) filtering}, 
year={2000}, 
pages={85-88}, 
abstract={We describe our initial work on generating augmented reality (AR) displays in the face of dynamically changing errors in the pose (position and orientation) of both the user and objects in the world. Dealing with this problem is particularly important in mobile AR environments, where the tracking accuracy of the user's head can change frequently and dramatically as she moves between areas with radically different tracking systems, such as in and out of buildings. We introduce the notion of level of error filtering, analogous to level of detail culling in 3D graphics systems, to help programmers build interfaces that automatically adapt to changing registration errors}, 
keywords={augmented reality;computer displays;image registration;mobile computing;user interfaces;3D graphics;augmented reality displays;dynamic registration errors;dynamically changing errors;level of detail culling;level of error filtering;mobile environments;tracking accuracy;user interfaces;Augmented reality;Computer displays;Computer errors;Filtering;Graphics;Registers;Resistors;Usability;Visualization;Wearable computers}, 
doi={10.1109/ISAR.2000.880927}, 
month={},}

@INPROCEEDINGS{6162897, 
author={A. Hill and J. Schiefer and J. Wilson and B. Davidson and M. Gandy and B. MacIntyre}, 
booktitle={Mixed and Augmented Reality (ISMAR), 2011 10th IEEE International Symposium on}, 
title={Virtual transparency: Introducing parallax view into video see-through AR}, 
year={2011}, 
pages={239-240}, 
abstract={In this poster, we present the idea of “virtual transparency” for video see-through AR. In fully synthetic 3D graphics, head-tracked motion parallax has been shown to be a powerful depth cue for understanding the structure of the virtual world. To leverage head-tracked motion parallax in video see-through AR, the view of the virtual and physical world must change together in response to head motion. We present a system for accomplishing this, and discuss the benefits and limitations of our approach.}, 
keywords={Augmented reality;Cameras;Head;Lenses;Three dimensional displays;Tracking;augmented reality;head tracking;motion parallax}, 
doi={10.1109/ISMAR.2011.6092395}, 
month={Oct},}
@INPROCEEDINGS{6402511, 
author={B. MacIntyre and G. Welch}, 
booktitle={Mixed and Augmented Reality (ISMAR), 2012 IEEE International Symposium on}, 
title={General chairs}, 
year={2012}, 
pages={1-2}, 
abstract={Welcome to the Eleventh IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR 2012)! We are excited that this year's symposium is being held on the campus of the Georgia Institute of Technology, at Georgia Tech's Hotel and Conference Center. Located in the center of Altanta, Georgia, USA, Georgia Tech is one of the top public research universities in the United States, and a nationally ranked leader in many of the academic disciplines that form the heart of ISMAR: Computer Science, Engineering, HCI, Robotics & Computer Vision, and Digital Media. Atlanta is one of the largest cities in the United States, often considered the “capital of the South” and played a central role in the American Civil War and the Civil Rights movement. With a diverse and young population, Atlanta is a dynamic city with many cultural and historic attractions, restaurants, shopping, sports and outdoor activities. Atlanta is served by Hartsfield-Jackson International Airport, the worlds busiest airport.}, 
doi={10.1109/ISMAR.2012.6402511}, 
month={Nov},}

@INPROCEEDINGS{6093647, 
author={M. Billinghurst and T. Langlotz and B. MacIntyre and H. Seichter}, 
booktitle={Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH), 2011 IEEE International Symposium On}, 
title={Authoring solutions for Augmented Reality}, 
year={2011}, 
pages={1-1}, 
abstract={The motivation of this workshop is to discuss future directions of content authoring in the field of Augmented Reality, as well as to discuss the current state of art on content creation and asset assembly. The workshop will comprise of a paper session where papers, late-breaking results and overviews over state-of-the-art in content authoring for AR are presented. In the afternoon, we will follow up with a discussion on different topics ranging from AR asset creation to content distribution and a closing session. Our goal is to collect ideas and thoughts of research about desired approaches for authoring content for AR, as well as review current and future needs to achieve a high quality content and at the same time scalable approaches for AR.}, 
doi={10.1109/ISMAR-AMH.2011.6093647}, 
month={Oct},}
@INPROCEEDINGS{4480752, 
author={T. Lang and B. MacIntyre and I. J. Zugaza}, 
booktitle={Virtual Reality Conference, 2008. VR '08. IEEE}, 
title={Massively Multiplayer Online Worlds as a Platform for Augmented Reality Experiences}, 
year={2008}, 
pages={67-70}, 
abstract={Massively Multiplayer Online Worlds (MMOs) are persistent virtual environments where people play, experiment and socially interact. In this paper, we demonstrate that MMOs also provide a powerful platform for Augmented Reality (AR) applications, where we blend together locations in physical space with corresponding places in the virtual world. We introduce the notion of AR stages, which are persistent, evolving spaces that encapsulate AR experiences in online three-dimensional virtual worlds. We discuss the concepts and technology necessary to use an MMO for AR, including a novel set of design concepts aimed at keeping such a system easy to learn and use. By leveraging the features of the commercial MMO Second Life, we have created a powerful AR authoring environment accessible to a large, diverse set of users.}, 
keywords={augmented reality;authoring systems;computer games;user interfaces;augmented reality;authoring environment;massively multiplayer online worlds;online three-dimensional virtual world;second life;user interface;Augmented reality;Collaborative work;Graphics;Information systems;Multimedia systems;Second Life;Space technology;User interfaces;Virtual environment;Virtual reality;Augmented Reality;H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realitiesÂ¿;I.3.7 [Three-Dimensional Graphics and Realism]: Virtual realityÂ¿;Massively Multi-player Online Worlds;Second Life;User Interfaces;Virtual Reality}, 
doi={10.1109/VR.2008.4480752}, 
month={March},}

@ARTICLE{1528428, 
author={B. MacIntyre and M. A. Livingston}, 
journal={IEEE Computer Graphics and Applications}, 
title={Guest Editors' Introduction: Moving Mixed Reality into the Real World}, 
year={2005}, 
volume={25}, 
number={6}, 
pages={22-23}, 
abstract={The guest editors introduce this special issue on Moving Mixed Reality into the Real World. The four theme articles represent a balanced view of the challenges in dealing with the problems of creating mixed reality systems in the real world.}, 
keywords={augmented reality;mixed reality;Aerospace industry;Application software;Augmented reality;Automotive engineering;Computer displays;Computer graphics;Defense industry;Merging;Prototypes;Virtual reality;augmented reality;mixed reality;Computer Graphics;Computer Simulation;Models, Theoretical;Multimedia;Systems Integration;User-Computer Interface}, 
doi={10.1109/MCG.2005.132}, 
ISSN={0272-1716}, 
month={Nov},}

@INPROCEEDINGS{6402561, 
author={I. Radu and B. MacIntyre}, 
booktitle={Mixed and Augmented Reality (ISMAR), 2012 IEEE International Symposium on}, 
title={Using children's developmental psychology to guide augmented-reality design and usability}, 
year={2012}, 
pages={227-236}, 
abstract={Augmented reality (AR) designers have great potential to enrich children's lives through AR experiences in education and entertainment. A significant difficulty in designing for children is that tremendous physical and cognitive development occurs across the first 10 years of life, and the changes in children's capabilities and limitations impact how these users respond to AR designs. Currently, little is known about how developmental changes relate to AR designs, or what AR designs are effective for young children. In this work, we focus on children 6-9 years old, presenting several concepts from developmental psychology and discussing how these relate to AR designs. Specifically, we investigate children's skills in the categories of motor abilities, spatial cognition, attention, logic and memory, and we discuss the relationship of these skills to current and hypothetical AR designs. Through this work, we intend to strengthen the field's understanding of AR usability and design, resulting in the generation of effective AR experiences for young users.}, 
keywords={augmented reality;human factors;psychology;software reusability;AR designs;AR experiences;attention;augmented-reality design;augmented-reality usability;children developmental psychology;children skills;cognitive development;education;entertainment;logic;memory;motor abilities;physical development;spatial cognition;Augmented reality;Cameras;Games;Guidelines;Muscles;Performance evaluation;Psychology;Augmented Reality;Children;Interaction Design;Mixed Reality;Psychology}, 
doi={10.1109/ISMAR.2012.6402561}, 
month={Nov},}
@INPROCEEDINGS{4538833, 
author={C. M. Robertson and B. MacIntyre}, 
booktitle={Mixed and Augmented Reality, 2007. ISMAR 2007. 6th IEEE and ACM International Symposium on}, 
title={An Evaluation of Graphical Context as a Means for Ameliorating the Effects of Registration Error}, 
year={2007}, 
pages={99-110}, 
abstract={An ongoing research problem in Augmented Reality (AR) is to improve tracking and display technology in order to minimize registration errors. However, perfect registration is not always necessary for users to understand the intent of an augmentation. This paper describes the results of an experiment to evaluate the effects of registration error in a Lego block placement task and the effectiveness of graphical context at ameliorating these effects. Three types of registration error were compared: no error, fixed error and random error. These three errors were evaluated with no context present and some graphical context present. The results of this experiment indicated that adding graphical context to a scene in which some registration error is present can allow a person to effectively operate in such an environment, in this case completing the Lego block placement task with a reduced number of errors made and in a shorter amount of time.}, 
keywords={augmented reality;computer displays;human computer interaction;image registration;Lego block placement task;augmented reality;computer displays;human-computer interaction;registration error;Adaptive systems;Augmented reality;Back;Computer displays;Graphics;Layout;Multimedia systems;Programming profession;Uncertainty;Visualization;augmented environments;augmented reality;communicative intent;human-computer interaction}, 
doi={10.1109/ISMAR.2007.4538833}, 
month={Nov},}

@INPROCEEDINGS{6402527, 
author={M. Billinghurst and T. Langlotz and B. MacIntyre and H. Seichter}, 
booktitle={Mixed and Augmented Reality (ISMAR), 2012 IEEE International Symposium on}, 
title={Workshop 1: 2nd IEEE ISMAR workshop on authoring solutions for augmented reality}, 
year={2012}, 
pages={1-2}, 
abstract={The motivation of this workshop is to discuss future direction of content authoring in the field of Augmented Reality, as well as to discuss the current state of art on content creation and content authoring for augmented reality. The workshop will comprise of a paper session where authoring papers, late-breaking results and overviews over state-of-the-art are presented. In the afternoon, we will follow up with discussion sessions on different topics ranging from content creation and authoring to content distribution for AR and a short closing session.}, 
doi={10.1109/ISMAR.2012.6402527}, 
month={Nov},}

@INPROCEEDINGS{6093652, 
author={Y. Xu and E. Barba and I. Radu and M. Gandy and R. Shemaka and B. Schrank and B. MacIntyre and T. Tseng}, 
booktitle={Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH), 2011 IEEE International Symposium On}, 
title={Pre-patterns for designing embodied interactions in handheld augmented reality games}, 
year={2011}, 
pages={19-28}, 
abstract={The game industry and related research communities have shown a surge of interest in reality-based interfaces that create “embodied” game play experiences. Handheld AR (HAR) is a reality-based interface that renders digital objects onto a player's perception of the physical world. HAR creates a hybrid space in which players can leverage their existing physical and social skills to interact with the game system and with each other. Although HAR has received some attention in the world of handheld gaming, there is little research that summarizes and communicates design principles and implications across multiple examples. In this paper, we analyze and generate design lessons from dozens of HAR games, drawn from academic and commercial AR games, and also our years of experience designing and teaching HAR game design. We summarize our experience in this new field into a set of design “pre-patterns” as a means of formalizing significant design lessons derived from these existing practices into repeatable principles and solutions. We contribute to both the game and interaction design communities with pre-patterns that support embodied game play.}, 
keywords={augmented reality;computer games;human computer interaction;social aspects of automation;user interfaces;HAR game design;embodied game play experiences;embodied interactions;game industry;game system;handheld augmented reality games;physical skills;reality-based interfaces;social skills;Augmented reality;Communities;Games;Handheld computers;Lenses;Physics;Smart phones;Handheld augmented reality interface;design patterns;game design;game interface}, 
doi={10.1109/ISMAR-AMH.2011.6093652}, 
month={Oct},}

@ARTICLE{1321027, 
author={N. Liogkas and B. MacIntyre and E. D. Mynatt and Y. Smaragdakis and E. Tilevich and S. Voida}, 
journal={IEEE Pervasive Computing}, 
title={Automatic partitioning for prototyping ubiquitous computing applications}, 
year={2004}, 
volume={3}, 
number={3}, 
pages={40-47}, 
abstract={A major challenge facing ubiquitous computing R&D is the difficulty of writing software for complex, distributed applications. Automatic application partitioning can help development teams rapidly prototype distributed ubiquitous computing systems.}, 
keywords={Java;open systems;research and development;software prototyping;Java;automatic application partitioning;distributed application;rapid prototyping;system architecture;ubiquitous computing R&D;Application software;Distributed computing;Humans;Java;Middleware;Pervasive computing;Programming profession;Prototypes;Software prototyping;Ubiquitous computing}, 
doi={10.1109/MPRV.2004.1321027}, 
ISSN={1536-1268}, 
month={July},}

@INPROCEEDINGS{1544672, 
author={M. Gandy and B. MacIntyre and P. Presti and S. Dow and J. Bolter and B. Yarbrough and N. O'Rear}, 
booktitle={Mixed and Augmented Reality, 2005. Proceedings. Fourth IEEE and ACM International Symposium on}, 
title={AR Karaoke: acting in your favorite scenes}, 
year={2005}, 
pages={114-117}, 
abstract={In this paper we present a concept for augmented reality entertainment, called AR Karaoke, where users perform their favorite dramatic scenes with virtual actors. AR Karaoke is the acting equivalent of traditional Karaoke, where the goal is to facilitate an acting experience for the user that is entertaining for both the user and audience. Prototype implementations were created to evaluate various user interfaces and design approach reveal guidelines that are relevant to the design of mixed reality applications in the domains of gaming, performance, and entertainment.}, 
keywords={augmented reality;computer games;entertainment;graphical user interfaces;humanities;AR Karaoke;augmented reality entertainment;entertainment;favorite dramatic scene;gaming;mixed reality application design;user interface;virtual actor;Application software;Augmented reality;DVD;Displays;Educational institutions;Layout;Prototypes;Software prototyping;User interfaces;Virtual reality}, 
doi={10.1109/ISMAR.2005.11}, 
month={Oct},}
@ARTICLE{1541964, 
author={S. Dow and B. MacIntyre and J. Lee and C. Oezbek and J. D. Bolter and M. Gandy}, 
journal={IEEE Pervasive Computing}, 
title={Wizard of Oz support throughout an iterative design process}, 
year={2005}, 
volume={4}, 
number={4}, 
pages={18-26}, 
abstract={The Wizard of Oz prototyping approach, widely used in human-computer interaction research, is particularly useful in exploring user interfaces for pervasive, ubiquitous, or mixed-reality systems that combine complex sensing and intelligent control logic. The vast design space for such nontraditional interfaces provides many possibilities for user interaction through one or more modalities and often requires challenging hardware and software implementations. The WOz method helps designers avoid getting locked into a particular design or working under an incorrect set of assumptions about user preferences, because it lets them explore and evaluate designs before investing the considerable development time needed to build a complete prototype.}, 
keywords={augmented reality;human computer interaction;software prototyping;ubiquitous computing;user interfaces;Wizard of Oz prototyping approach;complex sensing;human-computer interaction;intelligent control logic;iterative design process;mixed-reality system;pervasive system;ubiquitous system;user interface;Computational modeling;Intelligent control;Intelligent sensors;Intelligent systems;Iterative methods;Process design;Prototypes;Sensor systems;User interfaces;Virtual reality;HCI methods;Wizard of Oz;audio tours;design process;mixed reality;prototyping;ubiquitous computing}, 
doi={10.1109/MPRV.2005.93}, 
ISSN={1536-1268}, 
month={Oct},}
@INPROCEEDINGS{1191129, 
author={C. Wingrave and D. Hix and D. Schmalstieg and B. MacIntyre and D. Bowman and M. Mine}, 
booktitle={Virtual Reality, 2003. Proceedings. IEEE}, 
title={Mixed reality: the continuum from virtual to augmented reality}, 
year={2003}, 
pages={1218-1218}, 
abstract={Not Available}, 
keywords={Augmented reality;Collaborative tools;Corporate acquisitions;Displays;Interference;Terminology;User interfaces;Virtual reality}, 
doi={10.1109/VR.2003.1191129}, 
ISSN={1087-8270}, 
month={March},}
@INPROCEEDINGS{6483968, 
author={B. MacIntyre and G. Welch}, 
booktitle={Mixed and Augmented Reality (ISMAR-AMH), 2012 IEEE International Symposium on}, 
title={Gen chairs}, 
year={2012}, 
pages={1-2}, 
abstract={Welcome to the Eleventh IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR 2012)! We are excited that this year's symposium is being held on the campus of the Georgia Institute of Technology, at Georgia Tech's Hotel and Conference Center. Located in the center of Altanta, Georgia, USA, Georgia Tech is one of the top public research universities in the United States, and a nationally ranked leader in many of the academic disciplines that form the heart of ISMAR: Computer Science, Engineering, HCI, Robotics & Computer Vision, and Digital Media. Atlanta is one of the largest cities in the United States, often considered the “capital of the South” and played a central role in the American Civil War and the Civil Rights movement. With a diverse and young population, Atlanta is a dynamic city with many cultural and historic attractions, restaurants, shopping, sports and outdoor activities. Atlanta is served by Hartsfield-Jackson International Airport, the worlds busiest airport.}, 
doi={10.1109/ISMAR-AMH.2012.6483968}, 
month={Nov},}
@INPROCEEDINGS{5759610, 
author={J. Chen and G. Turk and B. MacIntyre}, 
booktitle={VR Innovation (ISVRI), 2011 IEEE International Symposium on}, 
title={Painterly rendering with coherence for augmented reality}, 
year={2011}, 
pages={103-110}, 
abstract={A seamless blending of the real and virtual worlds is key to increased immersion and improved user experiences for augmented reality (AR). Photorealistic and non-photorealistic rendering (NPR) are two ways to achieve this goal. Non-photorealistic rendering creates an abstract version of both the real and virtual world by stylization to make them indistinguishable. We present a painterly rendering algorithm for AR applications. This algorithm paints composed AR video frames with bump-mapping curly brushstrokes. Tensor fields are created for each frame to define the direction for the brushstrokes. We use tensor field pyramids to interpolate sparse tensor field values over the frame to avoid the numeric problems caused by global radial basis interpolation in existing algorithms. Due to the characteristics of AR applications we use only information from the current frame and previous frame to provide temporal coherence in two ways for the painted video. First, brushstroke anchors are warped from the previous frame to the current frame based on their neighbor feature points. Second, brushstroke appearances are reshaped by blending two parameterized brushstrokes to achieve better temporal coherence. The major difference between our algorithm and existing NPR work in general graphics and AR/VR areas is that we use feature points across AR frames to maintain coherence in the rendering. The use of tensor field pyramids and extra properties of brushstrokes, such as cut-off angles, are also novel features that extend exiting NPR algorithms.}, 
keywords={augmented reality;rendering (computer graphics);tensors;AR video frame;NPR algorithm;augmented reality;brushstroke appearance;bump mapping;neighbor feature point;nonphotorealistic rendering;painted video;painterly rendering;radial basis interpolation;sparse tensor field;temporal coherence;tensor field pyramid;virtual world blending;Coherence;Image edge detection;Interpolation;Optical imaging;Pixel;Rendering (computer graphics);Tensile stress}, 
doi={10.1109/ISVRI.2011.5759610}, 
month={March},}
@INPROCEEDINGS{4637328, 
author={C. M. Robertson and B. MacIntyre and B. N. Walker}, 
booktitle={Mixed and Augmented Reality, 2008. ISMAR 2008. 7th IEEE/ACM International Symposium on}, 
title={An evaluation of graphical context when the graphics are outside of the task area}, 
year={2008}, 
pages={73-76}, 
abstract={An ongoing research problem in Augmented Reality (AR) is to improve tracking and display technology in order to minimize registration errors. However, perfect registration is not always necessary for users to understand the intent of an augmentation. This paper describes the results of an experiment to evaluate the effects of graphical context in a Lego block placement task when the graphics are located outside of the task area. Four conditions were compared: fully registered AR; non-registered AR; a heads-up display (HUD) with the graphics always visible in the field of view; and a HUD with the graphics not always visible in the field of view. The results of this experiment indicated that registered AR outperforms both non-registered AR and graphics displayed on a HUD. The results also indicated that non-registered AR does not offer any significant performance advantages over a HUD, but is rated as less intrusive and can keep non-registered graphics from cluttering the task space.}, 
keywords={augmented reality;AR;Lego block placement task;augmented reality;graphical context;heads-up display;human-computer interaction;registration error minimization;Augmented reality;Chromium;Computer errors;Computer graphics;Layout;Multimedia systems;Programming profession;Psychology;Two dimensional displays;Virtual reality;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Evaluation/methodology;augmented environments;augmented reality;communicative intent;human-computer interaction}, 
doi={10.1109/ISMAR.2008.4637328}, 
month={Sept},}
@ARTICLE{5165561, 
author={N. Yankelovich and J. Slott and A. Hill and M. Bonner and J. Schiefer and B. MacIntyre and E. Mugellini and O. A. Khaled and F. Barras and J. Bapst and M. Back and E. Aviles-Lopez and J. A. Garcia-Macias}, 
journal={IEEE Pervasive Computing}, 
title={Building and Employing Cross-Reality}, 
year={2009}, 
volume={8}, 
number={3}, 
pages={55-57}, 
abstract={Considers present and future practical applications of cross-reality. From tools to build new 3D virtual worlds to the products of those tools, cross-reality is becoming a staple of our everyday reality. Practical applications of cross-reality include the ability to virtually visit a factory to manage and maintain resources from the comfort of your laptop or desktop PC as well as sentient visors that augment reality with additional information so that users can make more informed choices. Tools and projects considered are:Project Wonderland for multiuser mixed reality;ClearWorlds: mixed- reality presence through virtual clearboards; VICI (Visualization of Immersive and Contextual Information) for ubiquitous augmented reality based on a tangible user interface; Mirror World Chocolate Factory; and sentient visors for browsing the world.}, 
keywords={virtual reality;ClearWorlds;Mirror World Chocolate Factory;VICI;collaborative project;cross reality;multiuser mixed reality;project wonderland;sentient visors;virtual world;Augmented reality;Avatars;Collaborative software;Collaborative work;Displays;Information retrieval;Laboratories;Mirrors;Production facilities;User interfaces;ar;augmented reality;clearboards;cross reality;pervasive computing;project wonderland;sentient visor;tcho;virtual reality;vr}, 
doi={10.1109/MPRV.2009.41}, 
ISSN={1536-1268}, 
month={July},}
@INPROCEEDINGS{970538, 
author={B. MacIntyre and J. D. Bolter and E. Moreno and B. Hannigan}, 
booktitle={Augmented Reality, 2001. Proceedings. IEEE and ACM International Symposium on}, 
title={Augmented reality as a new media experience}, 
year={2001}, 
pages={197-206}, 
abstract={The authors discuss their work on applying media theory to the creation of narrative augmented reality (AR) experiences. We summarize the concepts of remediation and media forms as they relate to our work, argue for their importance to the development of a new medium such as AR, and present two examples AR experiences we have designed using these conceptual tools. In particular, we focus on leveraging the interaction between the physical and virtual world, remediating existing media (film, stage and interactive CD-ROM), and building on the cultural expectations of our users}, 
keywords={CD-ROMs;augmented reality;human factors;literature;user interfaces;AR experiences;conceptual tools;cultural expectations;interaction design;interactive CD-ROM;media forms;media theory;narrative augmented reality;new media experience;remediation;virtual world;Acceleration;Augmented reality;Buildings;CD-ROMs;Collaboration;Cultural differences;Displays;Graphics;HTML;Runtime}, 
doi={10.1109/ISAR.2001.970538}, 
month={},}
@INPROCEEDINGS{6162863, 
author={M. Billinghurst and T. Langlotz and B. MacIntyre and H. Seichter}, 
booktitle={Mixed and Augmented Reality (ISMAR), 2011 10th IEEE International Symposium on}, 
title={Authoring solutions for Augmented Reality}, 
year={2011}, 
pages={1-1}, 
abstract={The motivation of this workshop is to discuss future directions of content authoring in the field of Augmented Reality, as well as to discuss the current state of art on content creation and asset assembly. The workshop will comprise of a paper session where papers, late-breaking results and overviews over state-of-the-art in content authoring for AR are presented. In the afternoon, we will follow up with a discussion on different topics ranging from AR asset creation to content distribution and a closing session. Our goal is to collect ideas and thoughts of research about desired approaches for authoring content for AR, as well as review current and future needs to achieve a high quality content and at the same time scalable approaches for AR.}, 
doi={10.1109/ISMAR.2011.6092363}, 
month={Oct},}